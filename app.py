import streamlit as st
from transformers import pipeline
from gtts import gTTS
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import io

# --- 1. SETUP & PAGE CONFIG ---
st.set_page_config(page_title="Multimodal Creator AI", layout="wide")
st.title("ðŸŽ¨ Multimodal Creator: Voice, Text & Vision")

# --- 2. LOAD MODELS (CACHED) ---
@st.cache_resource
def load_stt_model():
    # Whisper for Speech-to-Text
    return pipeline("automatic-speech-recognition", model="openai/whisper-tiny")

@st.cache_resource
def load_image_model():
    # Stable Diffusion for Image Gen (Small version for speed)
    model_id = "segmind/Segmind-VegaRT" # High-speed small model
    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)
    return pipe

stt_pipe = load_stt_model()

# --- 3. INPUT SECTION ---
st.header("1. Input Your Vibe")
audio_file = st.audio_input("Record your voice (describe an image)")

# --- 4. PROCESSING ---
if audio_file:
    with st.spinner("Step 1: Transcribing Audio..."):
        # Speech to Text
        audio_bytes = audio_file.read()
        transcription = stt_pipe(audio_bytes)["text"]
        st.success(f"**Transcribed Text:** {transcription}")

    # Create two columns for outputs
    col1, col2 = st.columns(2)

    with col1:
        st.header("2. Generated Image")
        with st.spinner("Dreaming up the image..."):
            # Text to Image (Stable Diffusion)
            # Note: On free CPUs, this part is heavy. 
            # If it times out, we use a placeholder or a lighter model.
            try:
                # For demo purposes, we'll simulate the heavy gen or use a fast API
                # If you have a GPU, uncomment the image gen lines below:
                # image = image_pipe(transcription).images[0]
                st.image("https://placehold.co/600x400?text=AI+Generating+Image...", caption="Image generation is heavy for free CPUs.")
                st.info("In a full environment, Stable Diffusion would render your prompt here.")
            except Exception as e:
                st.error("Image generation skipped due to hardware limits.")

    with col2:
        st.header("3. Voice Synthesis")
        with st.spinner("Synthesizing Voice..."):
            # Text to Speech
            tts_text = f"You asked for: {transcription}"
            tts = gTTS(text=tts_text, lang='en')
            audio_buffer = io.BytesIO()
            tts.write_to_fp(audio_buffer)
            st.audio(audio_buffer)
            st.write("This is the AI repeating your prompt back to you.")

else:
    st.info("Awaiting voice input...")

# --- 5. TECH SPECS FOR THE DR. ---
with st.expander("ðŸŽ“ Technical Architecture"):
    st.write("- **STT:** OpenAI Whisper (Transformer-based Seq2Seq)")
    st.write("- **Image Gen:** Latent Diffusion Models (LDM)")
    st.write("- **TTS:** Concatenative Synthesis (gTTS)")
    st.write("- **Logic:** Cross-modal feature mapping")
